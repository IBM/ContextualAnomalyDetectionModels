{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook: Contextual Anomaly Detection (CAD) Device Creation\n",
    "\n",
    "This is the second of a series of three notebooks that show how the Contextual Anomaly Detection (CAD) Accelerator can be used to train and deploy a prediction interval model into Monitor using the Model Factory service endpoints.\n",
    "1.   Training: cookbooks/contextual_anomaly_train.ipynb\n",
    "2.  Monitor Device Creation: cookbooks/contextual_anomaly_create_device.ipynb\n",
    "3.   Model Deployment: cookbooks/contextual_anomaly_deploy_model.ipynb\n",
    "\n",
    "\n",
    "### CAD Description\n",
    "\n",
    "The CAD training job produces three prediction interval models that capture the normal operation (non-anomalous) behaviour of a given target variable based on a set of input features. \n",
    "\n",
    "These are point estimate multivariate regression machine learning models (denoted as base regressor) enhanced with conformal prediction statistical wrappers to produce a lower and upper bound that contain the target variable with probability 95% under normal operation (non-anomalous) conditions. Therefore, the probability of observing a target variable outside of the provided interval is 5% under normal operation conditions.\n",
    "\n",
    "### Wind Turbine Dataset Description: \n",
    "\n",
    "In this notebook we use the CAD Accelerator to learn a prediction interval model that covers the normal operation behaviour of the Average Reactive Power of a Wind turbine asset with probability 95%. We consider 4 input features to predict the target variable. These are Average Active Power, Average Generator Bearing 1 Temperature, Average Generator Bearing 2 Temperature, Average Wind Speed.\n",
    "\n",
    "### Device Creation Notebook Description\n",
    "\n",
    "This notebook shows an example of how the Model Factory Service can be used to create a monitor device needed before deploying the trained model. The device created in Monitor will contain as metrics the different variables of the dataset (features,target and time stamp).\n",
    "\n",
    "\n",
    "This is the SECOND notebook of our tutorial and should be run after 'cookbooks/contextual_anomaly_train.ipynb' since it requires the model specification file generated at the end of the CAD training notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a id='notebook_workflow'></a>\n",
    "### Notebook Workflow\n",
    "- [Imports](#imports)\n",
    "- [Load KPI specification file (yaml)](#load_kpiyaml)\n",
    "- [Load Model Factory config file (yaml)](#load_mfyaml)\n",
    "- [Load Model specification file (yaml)](#load_modelspecyaml)\n",
    "- [Prepare Payload to Create Monitor Device](#prepare_payload)\n",
    "- [Post Create Device Job ](#create_device_post)\n",
    "- [Request job log and summary](#job_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "483a0f8757a44528818b78c70cf7dfbc"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import yaml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load_kpiyaml'></a>\n",
    "### Load KPI specification file (yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This file is a dictionary containing:\n",
    "\n",
    "    - asset_id_column: column corresponding to asset id\n",
    "    - data_name: train dataset file name\n",
    "    - device_description: device description (optional)\n",
    "    - mas_device_name: monitor device name (needed for device creation and/or deployment)\n",
    "    - feature_columns: feature columns name as in first row of dataset csv file separated by ',' (e.g., P_avg,Rs_avg,Gb1t_avg,Ws_avg)\n",
    "    - feature_names: feature columns interpretable names separated by ',' (same order as in feature_columns)\n",
    "    - target_columns: target column name as in first row of dataset\n",
    "    - target_names: target column interpretable name\n",
    "    - timestamp_column: time stamp column name as in first row of dataset\n",
    "    - timestamp_format: '%m/%d/%Y %H:%M'\n",
    "    - inference_data_name: test dataset file name (optional for inference)\n",
    "    - feature_map: dictionary mapping feature columns to descriptions (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name = \"../config/Pavg_kpi.yml\"\n",
    "\n",
    "with open(input_file_name, 'r') as file:\n",
    "    input_data = yaml.safe_load(file)\n",
    "\n",
    "print('KPI specification file: ')\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eefd11f558654f35a5da132dfbf27956"
   },
   "source": [
    "<a id='load_mfyaml'></a>\n",
    "### Load Model Factory config file (yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This file is a dictionary containing:\n",
    "\n",
    "    - endpoint_url: <ACTION: Replace with Model Factory endpoint URL>\n",
    "    - train_recipe_endpoint: recipe/supervised-anomaly (DON'T CHANGE)\n",
    "    - deploy_recipe_endpoint: deployment/monitor/model/create (DON'T CHANGE)\n",
    "    - create_device_recipe_endpoint: deployment/monitor/device/create (DON'T CHANGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_factory_config_file_name = \"../config/model_factory_config.yml\"\n",
    "\n",
    "\n",
    "with open(model_factory_config_file_name, 'r') as file:\n",
    "    model_factory_config = yaml.safe_load(file)\n",
    "\n",
    "print(model_factory_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1ed8c63b125498da0999e5c95b7a51b"
   },
   "source": [
    "<a id='load_modelspecyaml'></a>\n",
    "### Load Model specification file (yaml)\n",
    "\n",
    "This is the .yaml file saved in the last step of the contextual_anomaly_train.ipynb notebook. It is a dictionary containing the following information:\n",
    "\n",
    "    - onnx_model_uri : Model mlflow uri provided in the CAD training summary\n",
    "    - train_job_id : Model Factory CAD training job id\n",
    "    - mas_device_name : Name of the Monitor Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name = \"../config/model_info.yml\"\n",
    "\n",
    "with open(input_file_name, 'r') as file:\n",
    "    model_info_data = yaml.safe_load(file)\n",
    "\n",
    "print(model_info_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prepare_payload'></a>\n",
    "### Prepare Payload to Create Monitor Device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The create device payload requires the following files:\n",
    "\n",
    "- iot_credentials: This file is located in config/iot_credentials.yaml and is a dictionary containing the following information\n",
    "    - IOT_URL: <INSERT>\n",
    "    - IOT_API_KEY: <INSERT>\n",
    "    - IOT_API_TOKEN: <INSERT>\n",
    "    - model_api: /api/v0002/pipeline/models\n",
    "    - MAS_URL: <INSERT>\n",
    "    - X-api-key: <INSERT>\n",
    "    - X-api-token: <INSERT>\n",
    "    - mam_user_email: <INSERT>\n",
    "    - tenantId: <INSERT>\n",
    "\n",
    "\n",
    "- data_file: This file is a .csv file containing a single row of data (i.e., first two rows of ../data/Wind_Turbine_train.csv). In this example we use the file located in '../data/Wind_Turbine_Asset_Data.csv'\n",
    "\n",
    "- assetmodel_file: This file is a .csv file containing 4 columns corresponding to dimension (name of variable/feature), type, label and columntype (following Monitor convention). In this example we use the file located in '../data/Wind_Turbine_Asset_Model.csv'\n",
    "\n",
    "- device_type_name: Name of mas device (this will be obtained from the Model Specification file, [see above](#load_modelspecyaml) )\n",
    "\n",
    "- device_type_description: Text description of the MAS device\n",
    "\n",
    "- metric_columns: The metric associated with the device and available as columns in the data_file.\n",
    "\n",
    "- timestamp_column: Time stamp column name (this will be obtained from the KPI specification file, [see above](#load-kpi-specification-file-yaml)).\n",
    "\n",
    "- assetid_column: Asset id column name (this will be obtained from the KPI specification file, [see above](#load-kpi-specification-file-yaml))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Credential File Path and Name\n",
    "'''\n",
    "\n",
    "credentials_file_path = \"../config/iot_credentials_beta.yaml\"\n",
    "credentials_file_name = \"iot_credentials_beta.yaml\"\n",
    "\n",
    "'''\n",
    "Data File Path and Name\n",
    "'''\n",
    "\n",
    "data_file_create_device_path = \"../data/Wind_Turbine_Asset_Data.csv\"\n",
    "data_file_create_device_name = \"Wind_Turbine_Asset_Data.csv\"\n",
    "\n",
    "'''\n",
    "assetmodel File Path and Name\n",
    "'''\n",
    "\n",
    "assetmodel_file_create_device_path = \"../data/Wind_Turbine_Asset_Model.csv\"\n",
    "assetmodel_file_create_device_name = \"Wind_Turbine_Asset_Model.csv\"\n",
    "\n",
    "\n",
    "'''\n",
    "Device Type Name and Description\n",
    "'''\n",
    "\n",
    "device_type_name = model_info_data['mas_device_name']\n",
    "device_type_description= 'Wind Turbine Device'\n",
    "\n",
    "'''\n",
    "Columns\n",
    "'''\n",
    "\n",
    "metric_columns = pd.read_csv(assetmodel_file_create_device_path)['dimension'].unique()\n",
    "metric_columns = \",\".join(metric_columns)\n",
    "\n",
    "timestamp_column = input_data['timestamp_column']\n",
    "assetid_column = input_data['asset_id_column']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {}\n",
    "payload[\"device_type_name\"] = device_type_name\n",
    "payload[\"device_type_description\"] = device_type_description\n",
    "payload[\"metric_columns\"] = metric_columns\n",
    "payload[\"timestamp_column\"] = timestamp_column\n",
    "payload[\"assetid_column\"] = assetid_column\n",
    "\n",
    "\n",
    "files = [\n",
    "    (\"iot_credentials\", (credentials_file_name, open(credentials_file_path), \"text/csv\")),\n",
    "    (\"data_file\", (data_file_create_device_name, open(data_file_create_device_path), \"text/csv\")),\n",
    "    (\"assetmodel_file\", (assetmodel_file_create_device_name, open(assetmodel_file_create_device_path), \"text/csv\")),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create_device_post'></a> \n",
    "### Post Create Device Job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url = model_factory_config[\"endpoint_url\"]\n",
    "create_device_url = endpoint_url + model_factory_config[\"create_device_recipe_endpoint\"]\n",
    "print(create_device_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "  'accept': 'application/json'\n",
    "}\n",
    "response = requests.post(create_device_url, data=payload, files=files, headers=headers)\n",
    "\n",
    "post_r_json = response.json()\n",
    "print(post_r_json)\n",
    "job_id = post_r_json['job_id']\n",
    "print('job id:',job_id )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='job_log'></a> \n",
    "### Request job log and summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = requests.get(endpoint_url + \"log/\" + job_id, headers=headers)\n",
    "print('LOGS :: ')\n",
    "if \"logs\" in logs.json():\n",
    "    print(logs.json()[\"logs\"])\n",
    "else:\n",
    "    print(logs.json())\n",
    "\n",
    "summary = requests.get(endpoint_url + \"summary/\" + job_id, headers=headers)\n",
    "print('SUMMARY :: ')\n",
    "print(summary.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook: Contextual Anomaly Detection (CAD) Model Deployment\n",
    "\n",
    "This is the second of a series of three notebooks that show how the Contextual Anomaly Detection (CAD) Accelerator can be used to train and deploy a prediction interval model into Monitor using the Model Factory service endpoints.\n",
    "1.   Training: cookbooks/contextual_anomaly_train.ipynb\n",
    "2.  Monitor Device Creation: cookbooks/contextual_anomaly_create_device.ipynb\n",
    "3.   Model Deployment: cookbooks/contextual_anomaly_deploy_model.ipynb\n",
    "\n",
    "\n",
    "### CAD Description\n",
    "\n",
    "The CAD training job produces three prediction interval models that capture the normal operation (non-anomalous) behaviour of a given target variable based on a set of input features. \n",
    "\n",
    "These are point estimate multivariate regression machine learning models (denoted as base regressor) enhanced with conformal prediction statistical wrappers to produce a lower and upper bound that contain the target variable with probability 95% under normal operation (non-anomalous) conditions. Therefore, the probability of observing a target variable outside of the provided interval is 5% under normal operation conditions.\n",
    "\n",
    "### Wind Turbine Dataset Description: \n",
    "\n",
    "In this notebook we use the CAD Accelerator to learn a prediction interval model that covers the normal operation behaviour of the Average Reactive Power of a Wind turbine asset with probability 95%. We consider 4 input features to predict the target variable. These are Average Active Power, Average Generator Bearing 1 Temperature, Average Generator Bearing 2 Temperature, Average Wind Speed.\n",
    "\n",
    "### Model Deployment Notebook Description\n",
    "\n",
    "This notebook shows an example of how we can deploy a trained CAD model into Monitor using the Model Factory Service. The deployed model will be configured as a streaming metric in the corresponding Monitor device.\n",
    "\n",
    "This is the THIRD notebook of our tutorial and should be run after 'cookbooks/contextual_anomaly_train.ipynb' and   'cookbooks/contextual_anomaly_create_device.ipynb' since it requires the model specification file saved at the end of the CAD training notebook and the corresponding Monitor Device created with the contextual_anomaly_create_device notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a id='notebook_workflow'></a>\n",
    "### Notebook Workflow\n",
    "- [Imports](#imports)\n",
    "- [Load Model Factory config file (yaml)](#load_mfyaml)\n",
    "- [Load Model specification file (yaml)](#load_modelspecyaml)\n",
    "- [Prepare Payload to Deploy Trained Model](#prepare_payload)\n",
    "- [Post Model Deployment Job](#deploy_model_post)\n",
    "- [Request job log and summary](#job_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "483a0f8757a44528818b78c70cf7dfbc"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import yaml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eefd11f558654f35a5da132dfbf27956"
   },
   "source": [
    "<a id='load_mfyaml'></a>\n",
    "### Load Model Factory config file (yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This file is a dictionary containing:\n",
    "\n",
    "    - endpoint_url: <ACTION: Replace with Model Factory endpoint URL>\n",
    "    - train_recipe_endpoint: recipe/supervised-anomaly (DON'T CHANGE)\n",
    "    - deploy_recipe_endpoint: deployment/monitor/model/create (DON'T CHANGE)\n",
    "    - create_device_recipe_endpoint: deployment/monitor/device/create (DON'T CHANGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'endpoint_url': 'http://127.0.0.1:8000/ibm/modelfactory/service/', 'train_recipe_endpoint': 'recipe/supervised-anomaly', 'deploy_recipe_endpoint': 'deployment/monitor/model/create', 'create_device_recipe_endpoint': 'deployment/monitor/device/create'}\n"
     ]
    }
   ],
   "source": [
    "model_factory_config_file_name = \"../config/model_factory_config.yml\"\n",
    "\n",
    "\n",
    "with open(model_factory_config_file_name, 'r') as file:\n",
    "    model_factory_config = yaml.safe_load(file)\n",
    "\n",
    "print(model_factory_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1ed8c63b125498da0999e5c95b7a51b"
   },
   "source": [
    "<a id='load_modelspecyaml'></a>\n",
    "### Load Model specification file (yaml)\n",
    "\n",
    "This is the .yaml file saved in the last step of the contextual_anomaly_train.ipynb notebook. It is a dictionary containing the following information:\n",
    "\n",
    "    - onnx_model_uri : Model mlflow uri provided in the CAD training summary\n",
    "    - train_job_id : Model Factory CAD training job id\n",
    "    - mas_device_name : Name of the Monitor Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mas_device_name': 'Wind_Turbine_Test_1', 'onnx_model_uri': 's3://testdataupload/38/2d3ee3fa6c0f4d80b0c6f22b379cf993/artifacts/PI_model_prefit_LGBM1_best.onnx', 'train_job_id': '7151b7c4-9ce1-477d-9792-2ab3569d4593'}\n"
     ]
    }
   ],
   "source": [
    "input_file_name = \"../config/model_info.yml\"\n",
    "\n",
    "with open(input_file_name, 'r') as file:\n",
    "    model_info_data = yaml.safe_load(file)\n",
    "\n",
    "print(model_info_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prepare_payload'></a>\n",
    "### Prepare Payload to Deploy Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The payload to deploy model into Monitor requires the following files:\n",
    "\n",
    "- iot_credentials: This file is located in config/iot_credentials.yaml and is a dictionary containing the following information\n",
    "    - IOT_URL: <INSERT>\n",
    "    - IOT_API_KEY: <INSERT>\n",
    "    - IOT_API_TOKEN: <INSERT>\n",
    "    - model_api: /api/v0002/pipeline/models\n",
    "    - MAS_URL: <INSERT>\n",
    "    - X-api-key: <INSERT>\n",
    "    - X-api-token: <INSERT>\n",
    "    - mam_user_email: <INSERT>\n",
    "    - tenantId: <INSERT>\n",
    "\n",
    "\n",
    "- mas_device_name: Name of mas device where the model should be deployed (this will be obtained from the Model Specification file, [see above](#load_modelspecyaml) )\n",
    "\n",
    "- onnx_model_uri: mlflow uri of the onnx model to be deployed (this will be obtained from the Model Specification file, [see above](#load_modelspecyaml) )\n",
    "\n",
    "- train_job_id: CAD training job id of the model that is being deployed (this will be obtained from the Model Specification file, [see above](#load_modelspecyaml) )\n",
    "\n",
    "- prepare_kpi_dashboard: Boolean indicating if a dashboard should be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Credential File Path and Name\n",
    "'''\n",
    "\n",
    "credentials_file_path = \"../config/iot_credentials_beta.yaml\"\n",
    "credentials_file_name = \"iot_credentials_beta.yaml\"\n",
    "\n",
    "\n",
    "'''\n",
    "Device Name, ONNX Model URI, Train Job ID \n",
    "'''\n",
    "\n",
    "mas_device_name = model_info_data['mas_device_name']\n",
    "onnx_model_uri = model_info_data['onnx_model_uri']\n",
    "train_job_id =  model_info_data['train_job_id']\n",
    "prepare_kpi_dashboard = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {}\n",
    "payload[\"onnx_model_uri\"] = onnx_model_uri\n",
    "payload[\"mas_device_name\"] = mas_device_name\n",
    "payload[\"train_job_id\"] = train_job_id\n",
    "payload['prepare_kpi_dashboard'] = prepare_kpi_dashboard\n",
    "\n",
    "files = [\n",
    "    (\"iot_credentials\", (credentials_file_name, open(credentials_file_path), \"text/csv\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='deploy_model_post'></a> \n",
    "### Post Model Deployment Job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8000/ibm/modelfactory/service/deployment/monitor/model/create\n"
     ]
    }
   ],
   "source": [
    "endpoint_url = model_factory_config[\"endpoint_url\"]\n",
    "deploy_recipe_endpoint = endpoint_url + model_factory_config[\"deploy_recipe_endpoint\"]\n",
    "print(deploy_recipe_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job_id': 'b5e1cb62-69ba-47e4-b1a6-23164ec090c9', 'message': 'Job b5e1cb62-69ba-47e4-b1a6-23164ec090c9 was submitted.', 'status': 'INITIALIZING'}\n",
      "job id: b5e1cb62-69ba-47e4-b1a6-23164ec090c9\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "  'accept': 'application/json'\n",
    "}\n",
    "response = requests.post(deploy_recipe_endpoint, data=payload, files=files, headers=headers)\n",
    "\n",
    "post_r_json = response.json()\n",
    "print(post_r_json)\n",
    "job_id = post_r_json['job_id']\n",
    "print('job id:',job_id )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='job_log'></a> \n",
    "### Request job log and summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGS :: \n",
      "recipe_file_path /tmp/ray/session_2023-11-20_20-43-06_133706_1/runtime_resources/working_dir_files/_ray_pkg_2d7293cea8265f5f/RecipeDeployONNX2IoT\n",
      "entrypoint_path /tmp/ray/session_2023-11-20_20-43-06_133706_1/runtime_resources/working_dir_files/_ray_pkg_2d7293cea8265f5f/main.py\n",
      "2023-11-21 01:52:05,943\tINFO worker.py:1329 -- Using address 172.63.0.4:6379 set in the environment variable RAY_ADDRESS\n",
      "2023-11-21 01:52:05,943\tINFO worker.py:1458 -- Connecting to existing Ray cluster at address: 172.63.0.4:6379...\n",
      "2023-11-21 01:52:05,971\tINFO worker.py:1633 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m172.63.0.4:8265 \u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m 2023/11/21 01:52:08 INFO mlflow.tracking.fluent: Experiment with name 'b5e1cb62-69ba-47e4-b1a6-23164ec090c9' does not exist. Creating a new experiment.\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m mlflow.experiment.name: b5e1cb62-69ba-47e4-b1a6-23164ec090c9\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m mlflow.experiment.id: 41\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m 2023/11/21 01:52:08 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m The git executable must be specified in one of the following ways:\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - be included in your $PATH\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - explicitly set via git.refresh()\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m All git commands will error until this is rectified.\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m This initial warning can be silenced or aggravated in the future by setting the\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m $GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - warn|w|warning|1: for a printed warning\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - error|e|raise|r|2: for a raised exception\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m Example:\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     export GIT_PYTHON_REFRESH=quiet\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m No matching run has been found.\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m Launching new run for entrypoint=deploy_onnx_model and parameters={'iot_credentials': 's3://testdataupload/b5e1cb62-69ba-47e4-b1a6-23164ec090c9_iot_credentials_beta.yaml', 'onnx_model_uri': 's3://testdataupload/38/2d3ee3fa6c0f4d80b0c6f22b379cf993/artifacts/PI_model_prefit_LGBM1_best.onnx', 'mas_device_name': 'Wind_Turbine_Test_1', 'train_job_id': '7151b7c4-9ce1-477d-9792-2ab3569d4593', 'prepare_kpi_dashboard': 'False'}\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m 2023/11/21 01:52:08 WARNING mlflow.tracking._tracking_service.utils: Failed to import Git (the git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m The git executable must be specified in one of the following ways:\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - be included in your $PATH\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - explicitly set via git.refresh()\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m All git commands will error until this is rectified.\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m This initial warning can be silenced or aggravated in the future by setting the\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m $GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - warn|w|warning|1: for a printed warning\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - error|e|raise|r|2: for a raised exception\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m Example:\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     export GIT_PYTHON_REFRESH=quiet\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m 2023/11/21 01:52:08 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m The git executable must be specified in one of the following ways:\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - be included in your $PATH\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - explicitly set via git.refresh()\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m All git commands will error until this is rectified.\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m This initial warning can be silenced or aggravated in the future by setting the\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m $GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - warn|w|warning|1: for a printed warning\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - error|e|raise|r|2: for a raised exception\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m Example:\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     export GIT_PYTHON_REFRESH=quiet\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m 2023/11/21 01:52:08 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m The git executable must be specified in one of the following ways:\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - be included in your $PATH\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - explicitly set via git.refresh()\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m All git commands will error until this is rectified.\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m This initial warning can be silenced or aggravated in the future by setting the\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m $GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - warn|w|warning|1: for a printed warning\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     - error|e|raise|r|2: for a raised exception\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m Example:\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m     export GIT_PYTHON_REFRESH=quiet\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m 2023/11/21 01:52:08 INFO mlflow.projects.utils: === Created directory /tmp/tmpjs_zzlev for downloading remote URIs passed to arguments of type 'path' ===\n",
      "\u001b[2m\u001b[36m(run_recipe_on_ray pid=1731)\u001b[0m 2023/11/21 01:52:08 INFO mlflow.projects.backend.local: === Running command 'python src/deployment/MAS/deploy_onnx_model.py --iot_credentials s3://testdataupload/b5e1cb62-69ba-47e4-b1a6-23164ec090c9_iot_credentials_beta.yaml --onnx_pimodel s3://testdataupload/38/2d3ee3fa6c0f4d80b0c6f22b379cf993/artifacts/PI_model_prefit_LGBM1_best.onnx --mas_device_name Wind_Turbine_Test_1 --train_job_id 7151b7c4-9ce1-477d-9792-2ab3569d4593 --prepare_kpi_dashboard False' in run with ID '471bb89447694ee0838efeb96c2c4e85' === \n",
      "\n",
      "SUMMARY :: \n",
      "{'job_id': 'b5e1cb62-69ba-47e4-b1a6-23164ec090c9', 'status': 'EXECUTING', 'detailed_summary': [{'run_id': '471bb89447694ee0838efeb96c2c4e85', 'experiment_id': '41', 'status': 'RUNNING', 'artifact_uri': 's3://testdataupload/41/471bb89447694ee0838efeb96c2c4e85/artifacts', 'start_time': '2023-11-21T01:52:08.804000+00:00', 'end_time': '', 'params.mas_device_name': 'Wind_Turbine_Test_1', 'params.iot_credentials': 's3://testdataupload/b5e1cb62-69ba-47e4-b1a6-23164ec090c9_iot_credentials_beta.yaml', 'params.train_job_id': '7151b7c4-9ce1-477d-9792-2ab3569d4593', 'params.onnx_model_uri': 's3://testdataupload/38/2d3ee3fa6c0f4d80b0c6f22b379cf993/artifacts/PI_model_prefit_LGBM1_best.onnx', 'params.prepare_kpi_dashboard': 'False', 'tags.mlflow.project.backend': 'local', 'tags.step': 'deploy_onnx_model', 'tags.mlflow.source.name': '/tmp/ray/session_2023-11-20_20-43-06_133706_1/runtime_resources/working_dir_files/_ray_pkg_2d7293cea8265f5f', 'tags.mlflow.runName': 'tasteful-vole-615', 'tags.mlflow.project.entryPoint': 'deploy_onnx_model', 'tags.mlflow.parentRunId': '6811dab605a2476d891c43747459be79', 'tags.recipe': 'supervised-anomaly', 'tags.mlflow.user': 'root', 'tags.mlflow.source.type': 'PROJECT'}, {'run_id': '6811dab605a2476d891c43747459be79', 'experiment_id': '41', 'status': 'RUNNING', 'artifact_uri': 's3://testdataupload/41/6811dab605a2476d891c43747459be79/artifacts', 'start_time': '2023-11-21T01:52:08.703000+00:00', 'end_time': '', 'params.mas_device_name': '', 'params.iot_credentials': '', 'params.train_job_id': '', 'params.onnx_model_uri': '', 'params.prepare_kpi_dashboard': '', 'tags.mlflow.project.backend': '', 'tags.step': '', 'tags.mlflow.source.name': '/usr/local/lib/python3.9/site-packages/ray/_private/workers/default_worker.py', 'tags.mlflow.runName': 'illustrious-skink-82', 'tags.mlflow.project.entryPoint': '', 'tags.mlflow.parentRunId': '', 'tags.recipe': 'supervised-anomaly', 'tags.mlflow.user': 'root', 'tags.mlflow.source.type': 'LOCAL'}]}\n"
     ]
    }
   ],
   "source": [
    "logs = requests.get(endpoint_url + \"log/\" + job_id, headers=headers)\n",
    "print('LOGS :: ')\n",
    "if \"logs\" in logs.json():\n",
    "    print(logs.json()[\"logs\"])\n",
    "else:\n",
    "    print(logs.json())\n",
    "\n",
    "summary = requests.get(endpoint_url + \"summary/\" + job_id, headers=headers)\n",
    "print('SUMMARY :: ')\n",
    "print(summary.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

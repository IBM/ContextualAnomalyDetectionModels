{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook: Contextual Anomaly Detection (CAD) Training\n",
    "\n",
    "This is the first of a series of three notebooks that show how the Contextual Anomaly Detection (CAD) Accelerator can be used to train and deploy a prediction interval model into Monitor using the API service endpoints.\n",
    "1.   Training: cookbooks/contextual_anomaly_train.ipynb\n",
    "2.  Monitor Device Creation: cookbooks/contextual_anomaly_create_device.ipynb\n",
    "3.   Model Deployment: cookbooks/contextual_anomaly_deploy_model.ipynb\n",
    "\n",
    "### CAD Description\n",
    "\n",
    "The CAD training job produces three prediction interval models that capture the normal operation (non-anomalous) behaviour of a given target variable based on a set of input features. \n",
    "\n",
    "These are point estimate multivariate regression machine learning models (denoted as base regressor) enhanced with conformal prediction statistical wrappers to produce a lower and upper bound that contain the target variable with probability 95% under normal operation (non-anomalous) conditions. Therefore, the probability of observing a target variable outside of the provided interval is 5% under normal operation conditions.\n",
    "\n",
    "\n",
    "The three CAD models are saved in ONNX format to be compatible with MAS, the user can choose which model to deploy based on the performance summary provided by the training job.\n",
    "\n",
    "### Wind Turbine Dataset Description: \n",
    "\n",
    "In this notebook we use the CAD Accelerator to learn a prediction interval model that covers the normal operation behaviour of the Average Reactive Power of a Wind turbine asset with probability 95%. We consider 4 input features to predict the target variable. These are Average Active Power, Average Generator Bearing 1 Temperature, Average Generator Bearing 2 Temperature, Average Wind Speed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e38a6433a43d481e863eac165f08b90d"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "<a id='notebook_workflow'></a>\n",
    "### Notebook Workflow\n",
    "- [Imports](#imports)\n",
    "- [Load KPI specification file (yaml)](#load_kpiyaml)\n",
    "- [Load API Service config file (yaml)](#load_mfyaml)\n",
    "- [Load Dataset](#load_dataset)\n",
    "- [Generate Training Payload](#cad_payload)\n",
    "- [Post Training Job](#cad_post)\n",
    "- [Request Training Summary](#cad_summary)\n",
    "- [Save Model Information](#cad_modelinfo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from time import sleep\n",
    "import yaml\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load_kpiyaml'></a>\n",
    "### Load KPI specification file (yaml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This file is a dictionary containing:\n",
    "\n",
    "    - asset_id_column: column corresponding to asset id\n",
    "    - data_name: train dataset file name\n",
    "    - device_description: device description (optional)\n",
    "    - mas_device_name: monitor device name (needed for device creation and/or deployment)\n",
    "    - feature_columns: feature columns name as in first row of dataset csv file separated by ',' (e.g., P_avg,Rs_avg,Gb1t_avg,Ws_avg)\n",
    "    - feature_names: feature columns interpretable names separated by ',' (same order as in feature_columns)\n",
    "    - target_columns: target column name as in first row of dataset\n",
    "    - target_names: target column interpretable name\n",
    "    - timestamp_column: time stamp column name as in first row of dataset\n",
    "    - timestamp_format: '%m/%d/%Y %H:%M'\n",
    "    - inference_data_name: test dataset file name (optional for inference)\n",
    "    - feature_map: dictionary mapping feature columns to descriptions (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name = \"../config/Pavg_kpi.yml\"\n",
    "\n",
    "with open(input_file_name, 'r') as file:\n",
    "    input_data = yaml.safe_load(file)\n",
    "\n",
    "print('KPI specification file: ')\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load_mfyaml'></a>\n",
    "### Load API Service config file (yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This file is a dictionary containing:\n",
    "\n",
    "    - endpoint_url: <ACTION: Replace with API Service endpoint URL>\n",
    "    - train_recipe_endpoint: recipe/supervised-anomaly (DON'T CHANGE)\n",
    "    - deploy_recipe_endpoint: deployment/monitor/model/create (DON'T CHANGE)\n",
    "    - create_device_recipe_endpoint: deployment/monitor/device/create (DON'T CHANGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_factory_config_file_name = \"../config/model_factory_config.yml\"\n",
    "\n",
    "with open(model_factory_config_file_name, 'r') as file:\n",
    "    model_factory_config = yaml.safe_load(file)\n",
    "\n",
    "print(model_factory_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6001440911584da8b4b10de7c669d2d7"
   },
   "source": [
    "<a id='load_dataset'></a>\n",
    "### Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "691fb319ef2740bb8da2b8805b8e2dc1"
   },
   "outputs": [],
   "source": [
    "prefix = \"../data/\"\n",
    "data_df_1 = pd.read_csv(prefix + input_data['data_name'])\n",
    "data_df_1.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9be9ca256c34047a8549c20cf84dbf8"
   },
   "source": [
    "<a id='cad_payload'></a>\n",
    "### Generate Training Payload\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "489d66dc848140fba409d531f9370e03"
   },
   "source": [
    "Training Payload Required Information (this will be read from the input_data dictionary loaded above)\n",
    "\n",
    "- Payload:\n",
    "    - \"feature_columns\": feature column names separated by ','\n",
    "    - \"target_columns\": target column name separated\n",
    "    - \"feature_names\": features descriptive names separated by ','\n",
    "    - \"target_names\": target descriptive name\n",
    "- files:\n",
    "    - \"data_file\": .csv data file with column names matching \"feature_columns\" and \"target_columns\" as specified in payroll.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dca956930214c1e8c3a4797148ed30f"
   },
   "outputs": [],
   "source": [
    "payload = {'feature_columns': input_data['feature_columns'],\n",
    "'feature_names': input_data['feature_names'],\n",
    "'target_columns': input_data['target_columns'],\n",
    "'target_names': input_data['target_names']}\n",
    "\n",
    "data_folder = \"../data/\"\n",
    "\n",
    "files=[\n",
    "  ('data_file',(input_data['data_name'],open(data_folder + input_data['data_name'],'rb'),'text/csv'))\n",
    "]\n",
    "\n",
    "print('Payload :')\n",
    "print(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cad_post'></a>\n",
    "### Post Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a118f181c50a43668d18d64b4415f4f0"
   },
   "outputs": [],
   "source": [
    "endpoint_url = model_factory_config[\"endpoint_url\"]\n",
    "training_endpoint_url = endpoint_url + model_factory_config[\"train_recipe_endpoint\"]\n",
    "\n",
    "headers = {\n",
    "  'accept': 'application/json'\n",
    "}\n",
    "start_time = time.time()\n",
    "\n",
    "response = requests.request(\"POST\", training_endpoint_url, headers=headers, data=payload, files=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5de01380142847308cb53ed70449e7a8"
   },
   "outputs": [],
   "source": [
    "post_r_json = response.json()\n",
    "print(post_r_json)\n",
    "job_id = post_r_json['job_id']\n",
    "print()\n",
    "print('job id:',job_id )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b851a7d5eecc445c9a25aad66d82931e"
   },
   "source": [
    "<a id='cad_summary'></a>\n",
    "### Request Training Summary\n",
    "\n",
    "The following code will obtain a summary after the training job is completed. This summary contains the performance of the three trained prediction interval models on test, train and validation data.\n",
    "We report the following metrics:\n",
    "- R2 score: indicates the R2 score of the base regressor, higher is better.\n",
    "- RMSE:  indicates the root mean square error of the base regressor, lower is better.\n",
    "- Coverage: indicates the probability of finding the groud truth target inside the produced interval (this value should be larger or equal to 0.95)\n",
    "- Mean Width: Indicates the average prediction interval width\n",
    "- Median Width: Indicates the median prediction interval width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7b47c2854f34dbe8e8c595a2d6e6f38"
   },
   "outputs": [],
   "source": [
    "\n",
    "log_url = endpoint_url + \"log/\"\n",
    "summary_url = endpoint_url + \"summary/\"\n",
    "\n",
    "print('Summary URL :: ')\n",
    "print(summary_url + job_id)\n",
    "print()\n",
    "while True:\n",
    "    get_response = requests.get(summary_url + job_id, headers={})\n",
    "    json_data = get_response.json()\n",
    "    print(\"json_data\",json_data)\n",
    "    if 'status' in json_data:\n",
    "        print('status :', json_data['status'])\n",
    "        print()\n",
    "        if json_data['status'] == 'DONE':\n",
    "            print()\n",
    "            print('-------------  Trained Models -------------  ')\n",
    "            print()\n",
    "            performance_dictionary = json_data['summary']['performance_dictionary']\n",
    "            for model in performance_dictionary.keys():\n",
    "                print('model name : ',model)\n",
    "                for key in performance_dictionary[model]:\n",
    "                    if key != 'performance':\n",
    "                        print(key, ' : ',performance_dictionary[model][key])\n",
    "                print()\n",
    "                print('Performance : ')\n",
    "                for dataset in performance_dictionary[model]['performance'].keys():\n",
    "                    print(dataset + ' set')\n",
    "                    print(performance_dictionary[model]['performance'][dataset])\n",
    "                    print()\n",
    "\n",
    "\n",
    "                print('----------------')\n",
    "                print()\n",
    "            finish_time = time.time()\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            print('STATUS : ',json_data['status'] )\n",
    "            print('retry later .... ')\n",
    "            sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Trained Model Names')\n",
    "print(performance_dictionary.keys())\n",
    "print('-----------------')\n",
    "print()\n",
    "\n",
    "''' !!ACTION :: Here you can choose any of the models in performance_dictionary.keys()'''\n",
    "model_selected = list(performance_dictionary.keys())[0]\n",
    "\n",
    "print('Selected Model is : ', model_selected)\n",
    "for key in performance_dictionary[model_selected]:\n",
    "    if key != 'performance':\n",
    "        print(key, ' : ',performance_dictionary[model_selected][key])\n",
    "print()\n",
    "print('Performance : ')\n",
    "for dataset in performance_dictionary[model_selected]['performance'].keys():\n",
    "    print(dataset + ' set')\n",
    "    print(performance_dictionary[model_selected]['performance'][dataset])\n",
    "    print()\n",
    "print('----------------')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cad_modelinfo'></a>\n",
    "### Save Model Information\n",
    "\n",
    "The information of the selected model is saved in 'config/model_info.yml'. This information will be needed for model deployment into Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'status' in json_data:\n",
    "    if json_data['status'] == 'DONE':\n",
    "        output_data = {\n",
    "            \"onnx_model_uri\" : performance_dictionary[model]['model_uri'],\n",
    "            \"train_job_id\" : job_id,\n",
    "            \"mas_device_name\" : input_data['mas_device_name']\n",
    "        }\n",
    "        with open(\"../config/model_info.yml\",\"w\") as file:\n",
    "            yaml.dump(output_data, file)\n",
    "        print('Model Information: ')\n",
    "        print(output_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mf_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
